{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb362386",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator \n",
    "\n",
    "# DA301:  Advanced Analytics for Organisational Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98102ab3",
   "metadata": {},
   "source": [
    "## Demostration video: Create a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71beff79",
   "metadata": {},
   "source": [
    "#### *This is a possible solution to the demostration video.* \n",
    "\n",
    "In this tutorial I’ll demonstrate step by step how to fit a classification decision tree model on the data set from the Telcom National study.\n",
    "\n",
    "A decision tree is a type of ML algorithm. It is a tree-like model of questions and decisions with their possible consequences, outcomes, resources costs, and utility. It is a graphic representation of various alternative solutions available at a certain point in time. Simply stated, the decision tree, which is based on how humans reason, is created by answering several questions that are continued after each affirmative or negative answer until a final choice can be made.\n",
    "\n",
    "For example, the decision-making process for deciding whether to stay living at your current location or move to another country may lead you to consider what to do with your possessions, and then, for example, to a range of more or less affordable (and reliable) options.\n",
    "\n",
    "Consider the following scenario:\n",
    "\n",
    "Telcom National (TN) wants to determine if a customer is likely to churn; in other words, they want to be able to predict the likelihood of a new customer 'churning' or leaving a specific service provider. As a data analyst, we will explore the decision tree model and how we can utilise it to get a satisfactory answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63f70d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb28fb",
   "metadata": {},
   "source": [
    "# 1. Prepare your workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries.\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as scp\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "# Provides classes and functions to estimate many different statistical methods.\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "# Note: Helps split data into sets to create BLR.\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note: Indicates situations that aren’t necessarily exceptions.\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "# Read the provided CSV file/data set.\n",
    "df = pd.read_csv('customer_data.csv')  \n",
    "\n",
    "# Print a summary of the DataFrame to sense-check it.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5f599",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e8b9a",
   "metadata": {},
   "source": [
    "# 2. Update variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ade549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the DataFrame column and add/determine the values.\n",
    "df['Edu'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update all the details of the education column.\n",
    "df.loc[df['Edu'].str.contains('basic'),'Edu' ] = 'pre-school'\n",
    "df.loc[df['Edu'].str.contains('university'),'Edu' ] = 'uni'\n",
    "df.loc[df['Edu'].str.contains('high'),'Edu' ] = 'high-school'\n",
    "df.loc[df['Edu'].str.contains('professional') ,'Edu'] = 'masters'\n",
    "df.loc[df['Edu'].str.contains('illiterate'),'Edu' ] = 'other'\n",
    "df.loc[df['Edu'].str.contains('unknown'),'Edu' ] = 'other'\n",
    "\n",
    "# Display all the unique values/check changes.\n",
    "df['Edu'].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2585d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c092d5",
   "metadata": {},
   "source": [
    "# 3. Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c356a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name new DataFrame and convert categorical variables to dummy variables.\n",
    "cat_vars=['Occupation','Status','Edu','House','Loan',\n",
    "          'Comm','Month','DOW','Last_out']\n",
    "\n",
    "# Use the for loop keyword to specify what actions to\n",
    "# apply to all the 'var' items.\n",
    "# Specify what needs to apply to all the variables.\n",
    "for var in cat_vars:  \n",
    "    # Specify details of the categorical list.\n",
    "    cat_list = pd.get_dummies(df[var], prefix=var)  \n",
    "    # Indicate the joining of the DataFrames.\n",
    "    df = df.join(cat_list) \n",
    "\n",
    "df_fin = df.drop(cat_vars, axis=1) \n",
    "\n",
    "# We have already specified the column names. \n",
    "# This code snippet is only used in the video for explanation purposes.\n",
    "# Specify the column names:\n",
    "# cat_vars=['Occupation','Status','Edu','House','Loan',\n",
    "#           'Comm','Month','DOW','Last_out']\n",
    "\n",
    "# Set a temporary DataFrame and add values.\n",
    "df_vars = df.columns.values.tolist()  \n",
    "\n",
    "# Indicate what columns are kept.\n",
    "to_keep = [i for i in df_vars if i not in cat_vars] \n",
    "\n",
    "# Define new DataFrame.\n",
    "df_fin = df[to_keep]  \n",
    "\n",
    "# Print the column.\n",
    "df_fin.columns.values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53314eb8",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64bb26f",
   "metadata": {},
   "source": [
    "# 4. Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to use as df_fin and replace missing values with zero.\n",
    "df_fin = df_fin.fillna(0)  \n",
    "\n",
    "# Select necessary columns. \n",
    "nec_cols = [ 'Status_divorced', 'Status_married',\n",
    "            'Status_single', 'Status_unknown', \n",
    "            'Edu_high-school', 'Edu_masters', \n",
    "            'Edu_other', 'Edu_pre-school', \n",
    "            'Edu_uni', 'House_no', 'House_unknown',\n",
    "            'House_yes', 'Loan_no', 'Loan_unknown', \n",
    "            'Loan_yes', 'DOW_fri', 'DOW_mon']\n",
    "\n",
    "X = df_fin[nec_cols]\n",
    "y = df_fin['Target']\n",
    "\n",
    "# Create a new DataFrame and apply SMOTE as the target variable is not balanced.\n",
    "os = SMOTE(random_state=0)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Specify column values.\n",
    "columns = X_train.columns  \n",
    "# Specify the new data sets.\n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train)  \n",
    "\n",
    "# Create two DataFrames for X and one for y.\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Target'])\n",
    "\n",
    "# Print/check the DataFrame.\n",
    "print(\"Length of oversampled data is \",len(os_data_X))\n",
    "os_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22549420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if values in a column are balanced.\n",
    "os_data_y['Target'].value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635dd737",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84d564",
   "metadata": {},
   "source": [
    "# 5. Build and fit the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed14388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DecisionTreeClassifier class from sklearn. \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "\n",
    "# Create a classification decision tree classifier object as dtc. \n",
    "dtc = DecisionTreeClassifier(criterion='gini',\n",
    "                             max_depth=4,\n",
    "                             random_state=1)\n",
    "\n",
    "# Train the decision tree classifier.\n",
    "dtc = dtc.fit(os_data_X, os_data_y) \n",
    "\n",
    "# Predict the response for the test data set.\n",
    "y_pred = dtc.predict(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60126c6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba11cb4d",
   "metadata": {},
   "source": [
    "# 6. Determine the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fe2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn metrics module for accuracy calculation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use the print() function to display the confusion matrix results.\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Metrics for accuracy: (TP + TN)/(TP + FP + TN + FN).\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) \n",
    "\n",
    "# Metrics for precision: TP/(TP + FP).\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred)) \n",
    "\n",
    "# Metrics for recall: TP/(FN + TP).\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ceae5",
   "metadata": {},
   "source": [
    "> Extra code snippets for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed757d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Seaborn for visualisation.\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the confusion_matrix.\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display the confusion matrix. \n",
    "pd.DataFrame(confusion_matrix, index=['observed_notchurn','observed_churn'],\n",
    "columns=['predicted_notchurn', 'predicted_churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9176796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary package.\n",
    "from sklearn.metrics import classification_report  \n",
    "\n",
    "# Print a report on the model's accuracy.\n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a4d74",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81b518",
   "metadata": {},
   "source": [
    "# 7. Visualise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib to create a visualisation and the tree package from sklearn.\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import tree\n",
    "\n",
    "# Plot the decision tree to create the visualisation.\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "tree.plot_tree(dtc, fontsize=12)\n",
    "\n",
    "# Print the plot with plt.show().\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f116daf3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03b87e",
   "metadata": {},
   "source": [
    "# 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cfc353",
   "metadata": {},
   "source": [
    "What does the decision tree tell us? What can we report back to Telcom National?\n",
    "> Accuracy and recall indicate a good model fit. Although an accuracy of 73% is not as good as 82% (BLR model), we still get it more right than wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75002461",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
