{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd712c0",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator \n",
    "# Course 301: Advanced Analytics for Organisational Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449cc917",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is based on a video demonstration by your course convenor, Dr James Abdey, to learn creating random forests to predict the likelihood of a new customer ‘churning’ or leaving a specific service provider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd198e8",
   "metadata": {},
   "source": [
    "# 1. Prepare your workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import all the necessary packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn import svm \n",
    "\n",
    "# Read the data file with Pandas.\n",
    "df = pd.read_csv('customer_data.csv')  \n",
    "\n",
    "# Sense-check the data.\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b58ca1",
   "metadata": {},
   "source": [
    "# 2. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2812de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update all the details of the education column.\n",
    "df['Edu'][df['Edu'].str.contains('basic') ] = 'pre-school'\n",
    "df['Edu'][df['Edu'].str.contains('university') ] = 'uni'\n",
    "df['Edu'][df['Edu'].str.contains('high') ] = 'high-school'\n",
    "df['Edu'][df['Edu'].str.contains('professional') ] = 'masters'\n",
    "df['Edu'][df['Edu'].str.contains('illiterate') ] = 'other'\n",
    "df['Edu'][df['Edu'].str.contains('unknown') ] = 'other'\n",
    "\n",
    "df['Edu'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6603eb",
   "metadata": {},
   "source": [
    "# 3. Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name new DataFrame and convert categorical variables to dummy variables:\n",
    "cat_vars=['Occupation', 'Status', 'Edu', 'House', 'Loan',\n",
    "          'Comm', 'Month', 'DOW', 'Last_out']\n",
    "\n",
    "# Use the for loop keyword to specify what actions to apply to all the var items:\n",
    "# Specify what needs to apply to all the variables.\n",
    "for var in cat_vars: \n",
    "    \n",
    "    # This line of code is not needed if you use the second cat_list.\n",
    "    # This code was only used for explanation purposes in the video.\n",
    "    # cat_list='var'+'_'+var\n",
    "    \n",
    "    # Specify details of the categorical list.\n",
    "    cat_list = pd.get_dummies(df[var], prefix=var)  \n",
    "    # Indicate the joining of the DataFrames.\n",
    "    df1=df.join(cat_list)  \n",
    "    # Set old DataFrame with new df with dummy values.\n",
    "    df=df1  \n",
    "    \n",
    "    # This is a duplicate to the first line of code.\n",
    "    # This code was only used for explanation purposes in the video.\n",
    "    # cat_vars=['Occupation', 'Status', 'Edu', 'House', 'Loan',\n",
    "    #           'Comm', 'Month', 'DOW', 'Last_out']\n",
    "\n",
    "# Set a temporary DataFrame and add values.\n",
    "df_vars=df.columns.values.tolist()  \n",
    "\n",
    "# Indicate what columns are kept.\n",
    "to_keep=[i for i in df_vars if i not in cat_vars] \n",
    "\n",
    "# Define new DataFrame.\n",
    "df_fin=df[to_keep]\n",
    "\n",
    "# Print the column.\n",
    "df_fin.columns.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8806de",
   "metadata": {},
   "source": [
    "# 4. Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE as the target variable is not balanced.\n",
    "df_fin = df_fin.fillna(0)\n",
    "\n",
    "# Select only the necessary columns and variables: \n",
    "nec_cols = ['Status_divorced', 'Status_married',\n",
    "            'Status_single', 'Status_unknown', \n",
    "            'Edu_high-school', 'Edu_masters', \n",
    "            'Edu_other', 'Edu_pre-school', \n",
    "            'Edu_uni', 'House_no', 'House_unknown',\n",
    "            'House_yes', 'Loan_no', 'Loan_unknown', \n",
    "            'Loan_yes', 'DOW_fri', 'DOW_mon']\n",
    "\n",
    "# Set the independent variables.\n",
    "X = df_fin[nec_cols]  \n",
    "# Set the dependent variable.\n",
    "y = df_fin.loc[:, df_fin.columns == 'Target']  \n",
    "\n",
    "# Create a new DataFrame and [4a] apply SMOTE as the target variable is not balanced.\n",
    "os = SMOTE(random_state=0)  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Specify column values. \n",
    "columns = X_train.columns  \n",
    "\n",
    "# Perform oversampling.\n",
    "# Specify the new data sets. \n",
    "os_data_X,os_data_y = os.fit_resample(X_train, y_train)    \n",
    "\n",
    "# Create two DataFrames for X and one for y from oversampling:\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Target'])\n",
    "\n",
    "# Print the DataFrame.\n",
    "print(\"length of oversampled data is \",len(os_data_X))  \n",
    "os_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49853a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if values are balanced.\n",
    "os_data_y['Target'].value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c3c27",
   "metadata": {},
   "source": [
    "# 5. Build and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier class.\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "# Create a forest object based on the RandomForestClassifier:\n",
    "forest = RandomForestClassifier(n_estimators=200, criterion='gini', \n",
    "                                min_samples_split=2, min_samples_leaf=2, \n",
    "                                max_features='auto', bootstrap=True, n_jobs=-1, \n",
    "                                random_state=42)\n",
    "\n",
    "\n",
    "# Train and predict the model:\n",
    "forest.fit(X_train, y_train)  \n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "# Import scikit-learn metrics module for accuracy calculation.\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model accuracy, how often is the model correct?\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8910e78",
   "metadata": {},
   "source": [
    "# 6. Visualise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62698eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages:\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Plot the decision tree to create the visualisation:\n",
    "fig, axes = plt.subplots(nrows = 1,\n",
    "                         ncols = 1,\n",
    "                         figsize = (4,4),\n",
    "                         dpi=800)\n",
    "\n",
    "tree.plot_tree(forest.estimators_[0],\n",
    "               filled = True);\n",
    "\n",
    "# Print and save the plot.\n",
    "fig.savefig('rf_individualtree.png')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e16fc",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1da3dd",
   "metadata": {},
   "source": [
    "# Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967e287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75ea60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ee7a45",
   "metadata": {},
   "source": [
    "# Accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c635ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aedbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cabe6148",
   "metadata": {},
   "source": [
    "# Determine feature significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a26101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb4d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
